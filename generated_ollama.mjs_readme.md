
```
This readme autogenerated in 195.8s (7.6tps) by h2t_70b_iq4_xs:latest
```

Ollama Wrapper Library README
=============================

Introduction
------------

The Ollama Wrapper Library is a JavaScript library that provides an easy-to-use interface for interacting with the Ollama API. This library allows you to access various endpoints of the Ollama API, including text generation, chat, and model management.

Quickstart Guide
---------------

To get started with the Ollama Wrapper Library, follow these steps:

1. Install the library using npm or yarn:
```
npm install ollama-wrapper
```
or
```
yarn add ollama-wrapper
```

2. Import the library in your JavaScript file:
```javascript
import Ollama from 'ollama-wrapper';
```

3. Create an instance of the Ollama object, passing in the URL of the Ollama API endpoint and optionally a default model name:
```javascript
const ollama = new Ollama('http://localhost:11434', 'llama');
```

4. Use the methods on the Ollama object to interact with the API endpoints. For example, you can use the `generate` method to generate text based on a prompt:
```javascript
ollama.generate({ prompt: 'Hello, world!' }).then(response => {
  console.log(response.message.content);
});
```

Methods Overview
---------------

The Ollama object provides the following methods for interacting with the API endpoints:

### ps()

Returns an array of models currently loaded in memory.

* Parameters: None
* Return Type: Promise<{models: string[]}>

### tags()

Returns an array of available models on the server.

* Parameters: None
* Return Type: Promise<{models: string[]}>

### generate(options)

Generates text based on a prompt or other options. If `options` is a string, it will be treated as a prompt using the default model. Otherwise, `options` should be an object containing one of more of the following properties:

* `prompt`: The input prompt to generate text from.
* `model`: The name of the model to use for generation (defaults to the instance's default model).
* `stream`: Whether to stream the response as it is generated (default: true).

* Parameters: options (string or { prompt: string, model?: string, stream?: boolean })
* Return Type: Promise<{ message: { content: string } }>

### chat(options)

Initiates a chat session with the model. If `options` is a string, it will be treated as an initial message using the default model. Otherwise, `options` should be an object containing one of more of the following properties:

* `message`: The initial message to send to the model.
* `model`: The name of the model to use for chat (defaults to the instance's default model).
* `stream`: Whether to stream the response as it is generated (default: true).

* Parameters: options (string or { message: string, model?: string, stream?: boolean })
* Return Type: Promise<{ message: { content: string } }>

### show(options)

Returns information about a specific model. If `options` is a string, it will be treated as the name of the model to show. Otherwise, `options` should be an object containing one of more of the following properties:

* `name`: The name of the model to show.
* `model`: The name of the model to use (defaults to the instance's default model).

* Parameters: options (string or { name: string, model?: string })
* Return Type: Promise<{ message: { content: string } }>

### pull(options)

Pulls a model from the server. If `options` is a string, it will be treated as the name of the model to pull. Otherwise, `options` should be an object containing one of more of the following properties:

* `name`: The name of the model to pull.

* Parameters: options (string or { name: string })
* Return Type: Promise<{ message: { content: string } }>

### delete(options)

Deletes a model from the server. If `options` is a string, it will be treated as the name of the model to delete. Otherwise, `options` should be an object containing one of more of the following properties:

* `name`: The name of the model to delete.

* Parameters: options (string or { name: string })
* Return Type: Promise<{ message: { content: string } }>

### create(options)

Creates a new model. `options` should contain the following properties:

* `name`: The name of the model to create.
* `config`: An object containing configuration settings for the model.

* Parameters: options ({ name: string, config: object })
* Return Type: Promise<{ message: { content: string } }>

### copy(options)

Copies an existing model. `options` should contain the following properties:

* `name`: The name of the model to copy.
* `new_name`: The new name for the copied model.

* Parameters: options ({ name: string, new_name: string })
* Return Type: Promise<{ message: { content: string } }>

### embeddings(options)

Returns the embedding vectors for a given input. If `options` is a string, it will be treated as the input text to compute embeddings for. Otherwise, `options` should be an object containing one of more of the following properties:

* `input`: The input text to compute embeddings for.
* `model`: The name of the model to use (defaults to the instance's default model).

* Parameters: options (string or { input: string, model?: string })
* Return Type: Promise<{ message: { content: string } }>

Instance Properties
-------------------

The Ollama object has one property:

### model

Gets or sets the default model name used by the instance. This property can be accessed and modified using the getter/setter syntax:
```javascript
const ollama = new Ollama('http://localhost:11434', 'llama');
console.log(ollama.model); // Output: "llama"
ollama.model = 'other_model';
console.log(ollama.model); // Output: "other_model"
```

This property is used by the `generate`, `chat`, and other methods to determine which model to use if no explicit model name is provided in the options object.

Error Handling
-------------

The Ollama Wrapper Library uses Promises to handle errors. If an error occurs during a request, the Promise will be rejected with an Error object containing information about the error.

For example:
```javascript
ollama.generate({ prompt: 'Hello, world!' }).catch(error => {
  console.error('Error:', error.message);
});
```

In this case, if an error occurs while generating text, the `catch` block will be executed and the error message will be logged to the console.

License
-------

The Ollama Wrapper Library is licensed under the MIT License. See the LICENSE file for details.

Contributing
------------

If you'd like to contribute to the Ollama Wrapper Library, please fork the repository on GitHub and submit a pull request with your changes.